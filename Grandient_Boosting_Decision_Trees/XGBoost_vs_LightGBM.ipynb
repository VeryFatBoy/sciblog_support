{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2330dbe5",
   "metadata": {},
   "source": [
    "# Gradient Boosting Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d73ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version:1.22.3\n",
      "Pandas version:1.4.1\n",
      "Sklearn version:1.0.2\n",
      "LightGBM version:3.3.2\n",
      "XGBoost version:1.5.2\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings (\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import json\n",
    "\n",
    "from utils import (Timer, load_airline, convert_related_cols_categorical_to_numeric, \n",
    "                   convert_cols_categorical_to_numeric)\n",
    "\n",
    "print(f\"Numpy version:{np.__version__}\")\n",
    "print(f\"Pandas version:{pd.__version__}\")\n",
    "print(f\"Sklearn version:{sklearn.__version__}\")\n",
    "print(f\"LightGBM version:{lgb.__version__}\")\n",
    "print(f\"XGBoost version:{xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29259979",
   "metadata": {},
   "source": [
    "## Airline dataset\n",
    "\n",
    "```bash\n",
    "cd data\n",
    "wget http://kt.ijs.si/elena_ikonomovska/datasets/airline/airline_14col.data.bz2\n",
    "bzip2 -dk airline_14col.data.bz2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_plane = load_airline()\n",
    "print(df_plane.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c8369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plane.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73dd7b7",
   "metadata": {},
   "source": [
    "The first step is to convert the categorical features to numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f96ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_plane_numeric = convert_related_cols_categorical_to_numeric(df_plane, col_list=['Origin','Dest'])\n",
    "del df_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecf10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_plane_numeric = convert_cols_categorical_to_numeric(df_plane_numeric, col_list='UniqueCarrier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433958b",
   "metadata": {},
   "source": [
    "To simplify the pipeline, we are going to set a classification problem where the goal is to classify wheather a flight has arrived delayed or not. For that we need to binarize the variable `ArrDelay`.\n",
    "\n",
    "If you want to extend this experiment, you can set a regression problem and try to identify the number of minutes of delay a fight has. Both XGBoost and LightGBM have regression classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plane_numeric = df_plane_numeric.apply(lambda x: x.astype('int16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_plane_numeric['ArrDelayBinary'] = 1*(df_plane_numeric['ArrDelay'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plane_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f01d20",
   "metadata": {},
   "source": [
    "Once the features are prepared, let's split the dataset into train and test set. We won't use validation for this example (however, you can try to add it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test_df(df, val_size=0.2, test_size=0.2):\n",
    "    train, validate, test = np.split(\n",
    "        df.sample(frac=1),\n",
    "        [int((1 - val_size - test_size) * len(df)), int((1 - test_size) * len(df))],\n",
    "    )\n",
    "    return train, validate, test\n",
    "\n",
    "def generate_feables(df):\n",
    "    X = df[df.columns.difference(['ArrDelay', 'ArrDelayBinary'])]\n",
    "    y = df['ArrDelayBinary']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train, validate, test = split_train_val_test_df(df_plane_numeric, val_size=0, test_size=0.2)\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, y_train = generate_feables(train)\n",
    "X_val, y_val = generate_feables(validate)\n",
    "X_test, y_test = generate_feables(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8908e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023db26",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Now we are going to create two pipelines, one of XGBoost and one for LightGBM. The technology behind both libraries is different, so it is difficult to compare them in the exact same model setting. XGBoost grows the trees depth-wise and controls model complexity with `max_depth`. Instead, LightGBM uses a leaf-wise algorithm and controls the model complexity by `num_leaves`. As a tradeoff, we use XGBoost with `max_depth=8`, which will have max number leaves of 255, and compare it with LightGBM with `num_leaves=255`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ada6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = dict()\n",
    "num_rounds = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468019e3",
   "metadata": {},
   "source": [
    "Let's start with the XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a59e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_pipeline = xgb.XGBRegressor(max_depth=8,\n",
    "                                    n_estimators=num_rounds,\n",
    "                                    min_child_weight=30,\n",
    "                                    learning_rate=0.1,\n",
    "                                    scale_pos_weight=2,\n",
    "                                    gamma=0.1,\n",
    "                                    reg_lambda=1,\n",
    "                                    subsample=1,\n",
    "                                    n_jobs=number_processors,\n",
    "                                    random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0aa79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    xgb_clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945954a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['xgb']={ 'train_time': t.interval }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864fb80d",
   "metadata": {},
   "source": [
    "Training XGBoost model with leave-wise growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc21d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_hist_clf_pipeline = xgb.XGBRegressor(max_depth=0,\n",
    "                                        max_leaves=255,\n",
    "                                        n_estimators=num_rounds,\n",
    "                                        min_child_weight=30,\n",
    "                                        learning_rate=0.1,\n",
    "                                        scale_pos_weight=2,\n",
    "                                        gamma=0.1,\n",
    "                                        reg_lambda=1,\n",
    "                                        subsample=1,\n",
    "                                        grow_policy='lossguide',\n",
    "                                        tree_method='hist',\n",
    "                                        n_jobs=number_processors,\n",
    "                                        random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58bf606",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    xgb_hist_clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['xgb_hist']={ 'train_time': t.interval }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5aa60d",
   "metadata": {},
   "source": [
    "Training LightGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffa6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf_pipeline = LGBMRegressor(num_leaves=255,\n",
    "                                  n_estimators=num_rounds,\n",
    "                                  min_child_weight=30,\n",
    "                                  learning_rate=0.1,\n",
    "                                  scale_pos_weight=2,\n",
    "                                  min_split_gain=0.1,\n",
    "                                  reg_lambda=1,\n",
    "                                  subsample=1,\n",
    "                                  nthread=number_processors,\n",
    "                                  seed=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    lgbm_clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c37a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['lgbm']={ 'train_time': t.interval }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2bdf5",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now let's evaluate the model in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c131af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_xgb = np.clip(xgb_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f01894",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['xgb']['test_time'] = t.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b423c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_xgb_hist = np.clip(xgb_hist_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bb11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['xgb_hist']['test_time'] = t.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    y_prob_lgbm = np.clip(lgbm_clf_pipeline.predict(X_test), 0.0001, 0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd7523",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['lgbm']['test_time'] = t.interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04b9db",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "We are going to obtain some metrics to evaluate the performance of each of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22122c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = binarize_prediction(y_prob_xgb)\n",
    "y_pred_xgb_hist = binarize_prediction(y_prob_xgb_hist)\n",
    "y_pred_lgbm = binarize_prediction(y_prob_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ba4ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb = classification_metrics_binary(y_test, y_pred_xgb)\n",
    "report2_xgb = classification_metrics_binary_prob(y_test, y_prob_xgb)\n",
    "report_xgb.update(report2_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['xgb']['performance'] = report_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6cf46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_xgb_hist = classification_metrics_binary(y_test, y_pred_xgb_hist)\n",
    "report2_xgb_hist = classification_metrics_binary_prob(y_test, y_prob_xgb_hist)\n",
    "report_xgb_hist.update(report2_xgb_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['xgb_hist']['performance'] = report_xgb_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_lgbm = classification_metrics_binary(y_test, y_pred_lgbm)\n",
    "report2_lgbm = classification_metrics_binary_prob(y_test, y_prob_lgbm)\n",
    "report_lgbm.update(report2_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c608cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['lgbm']['performance'] = report_lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6723e03",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb242fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(results_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del xgb_clf_pipeline, xgb_hist_clf_pipeline, lgbm_clf_pipeline, X_train, X_test, X_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (boosting)",
   "language": "python",
   "name": "boosting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
